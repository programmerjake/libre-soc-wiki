# SV Load and Store

Links:

* <https://bugs.libre-soc.org/show_bug.cgi?id=572>
* <https://llvm.org/devmtg/2016-11/Slides/Emerson-ScalableVectorizationinLLVMIR.pdf>

Vectorisation of Load and Store requires creation, from scalar operations, a number of different types:

* fixed stride (contiguous sequence with no gaps)
* element strided (sequential but regularly offset, with gaps)
* vector indexed (vector of base addresses and vector of offsets)

OpenPOWER Load/Store operations may be seen from [[isa/fixedload]] and [[isa/fixedstore]] pseudocode to be of the form:

    lbux RT, RA, RB
    EA <- (RA) + (RB)
    RT <- MEM(EA)

and for immediate variants:

    lb RT,D(RA)
    EA <- RA + EXTS(D)
    RT <- MEM(EA)

Thus in the first example, the source registers may each be independently marked as scalar or vector, and likewise the destination; in the second example only the one source and one dest may be marked as scalar or vector.

Thus we can see that Vector Indexed may be covered, and, as demonstrated with the pseudocode below, the immediate can be set to the element width in order to give unit stride.

At the minimum however it is possible to provide unit stride and vector mode, as follows:

    function op_ld(RT, RA, immed, update=False) # LD not VLD!
      rdv = map_dest_extra(RT);
      rsv = map_src_extra(RA);
      ps = get_pred_val(FALSE, RA); # predication on src
      pd = get_pred_val(FALSE, RT); # ... AND on dest
      for (int i = 0, int j = 0; i < VL && j < VL;):
        # skip nonpredicates elements
        if (RA.isvec) while (!(ps & 1<<i)) i++;
        if (RT.isvec) while (!(pd & 1<<j)) j++;
        if (RA.isvec)
          # indirect mode (multi mode)
          EA = ireg[rsv+i] + immoed;
          if update: ireg[rsv+i] = EA;
        elif (RT.isvec)
          # unit and element stride mode
          EA = ireg[rsv] + i * immed
          if update: ireg[rsv] = EA; # note: overwrites repeatedly
        else
          # standard scalar mode (but predicated)
          EA = ireg[rsv] + immed
          if update: ireg[rsv] = EA;
        ireg[rdv+j] <= MEM[EA];
        if (!RT.isvec)
            break # destination scalar, end immediately
        if (RA.isvec) i++;
        if (RT.isvec) j++;

Indexed LD is:
 
    function op_ldx(RT, RA, RB, update=False) # LD not VLD!
      rdv = map_dest_extra(RT);
      rsv = map_src_extra(RA);
      rso = map_src_extra(RB);
      ps = get_pred_val(FALSE, RA); # predication on src
      pd = get_pred_val(FALSE, RT); # ... AND on dest
      for (i=0, j=0, k=0; i < VL && j < VL && k < VL):
        # skip nonpredicated RA, RB and RT
        if (RA.isvec) while (!(ps & 1<<i)) i++; 
        if (RB.isvec) while (!(ps & 1<<k)) k++; 
        if (RT.isvec) while (!(pd & 1<<j)) j++; 
        EA = ireg[rsv+i] + ireg[rso+k] # indexed address
        if update: ireg[rsv+i] = EA
        ireg[rdv+j] <= MEM[EA];
        if (!RT.isvec)
            break # destination scalar, end immediately
        if (!RA.isvec && !RB.isvec)
            break # scalar-scalar
        if (RA.isvec) i++;
        if (RB.isvec) i++;
        if (RT.isvec) j++;

